exp_name: "my_experiment_name"

model:
  # detect classes number of model
  num_classes: 80
  # factor of model depth
  depth: 1.00
  # factor of model width
  width: 1.00
  # activation name. For example, if using "relu", then "silu" will be replaced with "relu".
  act: "silu"

dataloader:
  # If your training process costs a lot of memory, reduce this value.
  data_num_workers: 4
  # input size (height, width)
  input_size: [640, 640]
  # Actual multiscale ranges: [640 - 5 * 32, 640 + 5 * 32].
  # To disable multiscale training, set the value to 0.
  multiscale_range: 5
  # dir of dataset images, if data_dir is None, this project will use `datasets` dir
  data_dir: null
  # name of annotation file for training
  train_ann: "instances_train2017.json"
  # name of annotation file for evaluation
  val_ann: "instances_val2017.json"
  # name of annotation file for testing
  test_ann: "instances_test2017.json"

transform:
  # prob of applying mosaic augmentation
  mosaic_prob: 1.0
  # prob of applying mixup augmentation
  mixup_prob: 1.0
  # prob of applying hsv augmentation
  hsv_prob: 1.0
  # prob of applying flip augmentation
  flip_prob: 0.5
  # rotation angle range, for example, if set to 2, the true range is (-2, 2)
  degrees: 10.0
  # translate range, for example, if set to 0.1, the true range is (-0.1, 0.1)
  translate: 0.1
  # mosaic scale range
  mosaic_scale: [0.1, 2]
  # apply mixup augmentation or not
  enable_mixup: true
  # mixup scale range
  mixup_scale: [0.5, 1.5]
  # shear angle range, for example, if set to 2, the true range is (-2, 2)
  shear: 2.0

training:
  # epoch number used for warmup
  warmup_epochs: 5
  # max training epoch
  max_epoch: 300
  # minimum learning rate during warmup
  warmup_lr: 0
  # minimum learning rate ratio
  min_lr_ratio: 0.05
  # learning rate for one image. During training, lr will multiply by batch size.
  basic_lr_per_img: 0.01 / 64.0
  # name of LRScheduler
  scheduler: "yoloxwarmcos"
  # last #epoch to close augmentation like mosaic
  no_aug_epochs: 15
  # apply EMA during training
  ema: true
  # weight decay of optimizer
  weight_decay: 0.0005
  # momentum of optimizer
  momentum: 0.9
  # log period in iterations, for example, if set to 1, the user could see log every iteration.
  print_interval: 10
  # evaluation period in epochs, for example, if set to 1, the model will be evaluated after every epoch.
  eval_interval: 10
  # save history checkpoint or not.
  # If set to False, yolox will only save the latest and best checkpoints.
  save_history_ckpt: true

testing:
  # output image size during evaluation/test
  test_size: [640, 640]
  # confidence threshold during evaluation/test,
  # boxes whose scores are less than test_conf will be filtered
  test_conf: 0.01
  # NMS threshold
  nmsthre: 0.65
